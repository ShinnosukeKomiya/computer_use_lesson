このレッスンの終わりまでに、画像とテキストを組み合わせたマルチモーダルプロンプトを作成し、APIからのストリーミングレスポンスを扱えるようになります。
では始めましょう。
最初のマルチモーダルリクエストを作成していきます。画像や複数の画像をテキストと共にモデルに送信し、応答を得ます。
前回のビデオと同様に、基本的なセットアップがあります。Anthropicをインポートし、クライアントをセットアップし、モデル名の文字列を保存するヘルパー変数を用意します。
画像の作業を始める前に、これまで見てきたメッセージ構造についてもう少し説明する必要があります。
前回のレッスンでは、各メッセージにroleをuserに設定し、contentを「ジョークを教えて」のような文字列に設定したメッセージリストを作成しました。
これを実行すると、ジョークが返ってきます。良いジョークではありませんが、ジョークです。
これは実際にはショートカットです。contentを文字列に設定するのは、ここにある構文のショートカットです。contentをコンテンツブロックのリストを含むリストに設定します。
この場合、typeをtextに設定し、textを「ジョークを教えて」に設定した単一のコンテンツブロックです。
これにより、全く同じ入力プロンプトが得られますが、構文が異なります。
上記のように、単純にテキストプロンプトを行う場合は、この方が簡単です。しかし、すぐに分かるように、画像を提供する場合は、コンテンツブロックのリストを提供する必要があります。
これを実行すると、また別のジョークが返ってきます。
コンテンツブロックのリストについて説明するために、roleがuserでcontentがリストに設定された単一のメッセージがあります。
そして3つのテキストブロックが含まれています。それぞれ1つの単語のテキストがあります。
「Who」「made」「you」です。これを実行すると、「I was created by Anthropic」という応答が返ってきます。
これらのメッセージはすべて結合され、基本的に単一の入力プロンプトになります。
では画像に移りましょう。
私たちのClaudeモデルは画像を入力として受け付けます。そのため、作業用の画像が必要です。
使用する画像がいくつか含まれているimagesフォルダを提供しました。これが1つ目です。
仮に私たちがフードデリバリーのスタートアップを運営していて、Claudeを使用して顧客のクレームを確認するとします。
顧客がスクリーンショットを送ってきて、「注文の半分しか届いていない、返金してほしい」と言います。
そこで、この写真のような顧客の食事の画像をClaudeに分析してもらいます。
まずは簡単に始めて、この画像に含まれるボックスやカートンの数を教えてもらいましょう。
最初のステップは、画像を含むメッセージの構造を理解することです。
この図は構造を示しています。メッセージリストがあり、これまでと同様にroleはuserに設定され、contentリストがあることがわかります。
そしてcontentの中に、これまで見たことのない新しいタイプのコンテンツブロックがあります。これまではテキストブロックだけでしたが、これは画像ブロックです。
typeは画像に設定されています。これは辞書型で、sourceキーには別の辞書型が設定されています。
typeはbase64に設定され、media_typeは画像のメディアタイプ（JpegやPNG、GIFなど）に設定され、そして生の画像データがあります。
これが単一のメッセージの構造です。
ノートブックに戻ると、そのメッセージを実際に作成する前にいくつかのステップを踏む必要があります。
実際の画像ファイル自体を読み込む必要があります。
food.pngへのパスを使ってそれを開きます。
次に画像の内容をバイトオブジェクトとして読み込みます。
そしてバイナリデータをbase64を使ってエンコードします。
最後にbase64エンコードされたデータを文字列に変換します。
これでbase64文字列が得られましたが、かなり長いものです。
最初の100文字だけを見ると、このような感じです。
では、このbase64文字列（適切にフォーマットされた画像データを含む）を取り、適切にフォーマットされたメッセージに入れて、モデルに送信する必要があります。
ここに、food.png画像データをbase64文字列として含むbase64文字列を取り、適切にフォーマットされたコンテンツブロック、画像コンテンツブロックに入れるコードがあります。
ご覧のように、typeは画像に設定され、sourceは辞書型で、typeはbase64、これはPNGで、dataは巨大な変数base64stringに設定されています。
そして2つ目のコンテンツブロックが続きます。
今度はテキストコンテンツブロックで、「この画像には各タイプの持ち帰り容器が何個ありますか?」というテキストがあります。
非常にシンプルなプロンプトです。
食べ物が入った持ち帰り容器の画像を送り、それぞれのタイプが何個あるか知りたいと思います。
では、このメッセージリストをAPIに送信します。
これまで見てきたのと同じ構文を使用します。client.messages.createです。
messagesを渡します。実行します。
すると応答が返ってきます。
「この画像には、透明な蓋付きの長方形のプラスチック容器が3つと、白い紙またはダンボール製の折りたたみ式テイクアウトボックス（中華料理の持ち帰り箱やオイスターペイルと呼ばれる）が3つあります。」
これは正確です。
元の画像に戻ると、確かにプラスチックの蓋付きの箱が3つと、紙製のオイスターペイルまたは中華料理の持ち帰り容器が3つあります。
さて、画像を読み込んでbase64に変換し、UTF-8文字列に変換し、適切にフォーマットされたメッセージに追加するという全てのステップを何度も繰り返すのは少し面倒かもしれません。
そこで、ヘルパー関数を作るのに適しています。
これは、先ほど見た機能を組み合わせたヘルパー関数です。
create_image_messageと呼ばれ、画像パスを受け取ります。
そして先ほど見たステップを実行します。
画像を開いてバイナリデータを読み込み、base64エンコーディングでエンコードし、UTF-8文字列に変換します。
MIMEタイプを推測します。
PNG、JPEG、GIF、その他のフォーマットかを指定する必要があることを覚えておいてください。
最後に、適切にフォーマットされた画像ブロックを作成し、そのブロックを返します。
別の画像で試してみましょう。
imagesディレクトリにはplant.pngという画像があります。
これはウツボカズラです。
技術的にはネペンテスだと思います。
私自身、これを育てるのにあまり成功していません。
通常、捕虫袋が出る前に枯らしてしまいます。
でもとてもクールな植物です。
モデルに単純に植物を識別してもらいましょう。
非常にシンプルなユースケースです。
定義した関数を使用します。
新しいメッセージリストがあり、その中にroleがuserの単一のメッセージがあります。
contentはリストに設定され、plant.png画像に対するcreate_image_messageの結果が含まれています。
適切にフォーマットされたメッセージが返ってきます。
正確にはコンテンツブロックです。
そして、「この種は何ですか?」という非常にシンプルなプロンプトのテキストコンテンツブロックが続きます。
モデルに送信します。
実行して、応答を出力します。
こちらです。
「これはネペンテスウツボカズラのように見えます。これは食虫植物の一種で...」
などと続きます。
では、物事を少し簡単にするためのヘルパー関数でした。
さらに一歩進んで、画像パスと「この種は何ですか?」のようなテキストプロンプトを提供するだけで、メッセージリスト全体を生成するヘルパー関数を作ることもできます。
次に、多くの顧客がClaudeを使用して支援している、より現実的なユースケースを見てみましょう。
ドキュメントの分析です。
たくさんのドキュメント。
このような請求書を見てみましょう。これはinvoice.pngと呼ばれています。
重要な情報がたくさん含まれています。
PDFかもしれませんし、PNGかもしれません。
Claudeに入力できます。
良いプロンプトを与えて、構造化されたデータとして応答を求めることができます。
数千の請求書を数分でJSONに変換し、データベースに保存することができるかもしれません。
単一の例でどのようになるか見てみましょう。
このinvoice.png画像です。適切にフォーマットされた画像メッセージを提供します。
次にテキストプロンプト、かなりシンプルなものを提供します。
「この請求書の内容を表すJSONオブジェクトを生成してください。すべての日付、金額、住所を含める必要があります。JSONのみで応答してください。」
モデルに送信すると、JSONレスポンスが返ってきます。
会社名があります。私の会社、Acme Corporation、架空の住所です。
請求書に関する情報、請求書番号、日付、支払期限、請求先とその住所に関する情報があります。
請求書の項目です。
エンタープライズソフトウェアライセンス、実装サービス、プレミアムサポートプランです。
そして合計があります。
合計、税率、税額、実際の合計額を含みます。
スクロールして画像をよく見ると、この情報がすべて正確であることがわかります。
植物の種を識別するのに比べて、画像プロンプトのより現実的なユースケースです。
ここでは実演しませんが、重要な点として、1つのメッセージで複数の画像を提供することも可能です。
すべてのコンテンツブロックは、モデルに入力される際に、基本的に1つのプロンプトとして扱われることを覚えておいてください。
単一のユーザーメッセージの一部として、複数の画像ブロックと複数のテキストプロンプトブロックの組み合わせを提供できます。contentはリストです。
typeを画像に設定するか、テキストに設定するかに関係なく、コンテンツブロックを内部に追加するだけです。
このレッスンで扱う2つ目のトピックは、ストリーミングレスポンスです。
これまで見てきたclient.messages.createの使用は素晴らしいのですが、「詩を書いて」というようなプロンプトを与えると、応答全体が生成され準備できるまで待つ必要があることに気づくでしょう。
そのため、それほど時間はかかりません。
おそらく0.5秒か1秒以下で、生成全体を一度に受け取ります。
しかし、モデルの出力生成が長くなればなるほど、例えばモデルにエッセイを書かせる場合、何らかのコンテンツを受け取るまでの時間が長くなります。
出力全体が生成されるまで応答は返ってきません。
ストリーミングを使用すると、少し異なることができます。
コンテンツが生成されるにつれて、コンテンツを受け取ることができます。
これは、ユーザー向けのシナリオに最適です。
完全な生成が完了するのを待つのではなく、生成されている応答をユーザーに表示し始めることができます。
ストリーミングは実際には生成の全体的なプロセスを高速化しませんが、最初のトークンまでの時間、つまり最初の生命の兆候、応答の最初の部分が表示されるまでの時間を短縮します。
構文は少し異なりますが、このclient.messages.createと非常によく似ています。
ここでは、client.messages.streamになります。
max_tokensを渡し、メッセージのリストを渡していることに注目してください。
プロンプトは単純な「詩を書いて」です。
モデル名を渡します。
しかし、少し異なるのは、streamと呼ぶものを反復処理することです。
streamという名前を付け、stream.text_streamの中のすべてのテキストを反復処理し、出力します。
これを実行すると、内容が生成されるにつれて返ってくるのが分かります。全体が一度に生成されるのを待つ必要はありません。
もう一度試してみましょう。小さなチャンクが次々と返ってきて、それらを受け取りながら出力しているのが分かります。
ただし、この生成に要する全体的な時間は変わりません。リクエストごとに当然変動はありますが、ストリーミングを使用しなくても魔法のように全体の結果が早く得られるわけではありません。
単に出力が生成されるにつれて、その部分を得ているだけです。
これまでに、contentの一部として画像をプロンプトとして送信する方法と、モデルからレスポンスをストリーミングする方法を見てきました。
ここで再び、computer useクイックスタートの実装から実例を示したいと思います。
これは多くのことを行う関数ですが、このハイライトされたテキストをよく見ると、このレッスンで先ほど説明したフォーマットを使用して、正しくフォーマットされた画像を追加しているのが分かります。
typeは画像で、sourceは辞書型、typeはbase64です。これらの画像は何でしょうか？
これらは、モデルに提供しているスクリーンショットです。
このコースのcomputer useの概要で以前見たように、モデルはスクリーンショットを取得し、それを分析し、アクションを決定することで動作します。
そのため、モデルに画像を提供できる必要があります。このレッスンですでに見た構文をそのまま使用します。
これらの画像コンテンツブロックを作成します。植物を識別するよりもずっと複雑なユースケースですが、構文はまったく同じです。
このように、私たちのツールの武器庫は徐々に増えています。次は、より現実的で複雑なプロンプトについて説明します。
